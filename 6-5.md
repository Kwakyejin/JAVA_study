# 6-5 인스턴스 멤버와 정적 멤버

## 정의
1. 인스턴스 멤버 : 객체마다 가지고 있는 멤버

2. 정적 멤버 : 클래스에 위치시키고 객체들이 공유하는 멤버

for 메모리 낭비를 방지하기 위함

생각해보기. 필드값이 달라지게 된다면 객체마다 가지고 있는게 맞는가? 필드값이 같은 객체라면?

## 인스턴스 멤버
### 인스턴스 멤버 선언
앞에서 배운 것들은 다 거진 인스턴스 필드와 인스턴스 메소드였다. 
```java
public class car{
  //필드
  int gas;
  
  //메소드
  void setSpeed(int speed){...}
}

Car myCar = new Car();
myCar.gas = 10;
myCar.setSpeed(60);

Car myDaddyCar = new Car();
myDaddyCar.gas = 30;
myDaddyCar.setSpeed(100);
```

*중요*
![image](https://user-images.githubusercontent.com/81745747/128310733-024050bb-e2c4-4e72-8140-78f932a9840b.png)

### 인스턴스 멤버와 this
```java
public class car{
  //필드
  String model;
  int speed;
  
  //생성자
  Car(String model){
    this.model = model;
  }
  
  //메소드
  void setSpeed(int speed){
    this.speed = speed
  }
  
  void run(){
    for(int i=10; i<=50; i+=10){
      this.setSpeed(i);
      System.out.println(this.model + "가 달립니다.(시속:" + this.speed + "km/h)");
    }
  }
}
```


```java
package sec05.exam01;

public class CarExample {
	public static void main(String[] args) {
		Car myCar = new Car("포르쉐");
		Car yourCar = new Car("벤츠");
		
		myCar.run();
		yourCar.run();
	}
}
```

## 정적 멤버
### 정적 멤버 선언 -> 객체를 생성하지 않고 사용 가능

```java
public class Calculator {
  String color;
	static double pi = 3.14159;
}
```	

### 정적 멤버 사용 원칙 & 

**2. capture_img**

라즈베리파이 카메라 모듈을 카메라로 보이는 장면을 캡쳐해준다. resolution은 (240,240), frame rate는 32이고 찍으면 뒤집혀 찍히기 때문에 rotation을 180으로 설정해준다.
```py
camera = PiCamera()
img = 'img.jpg'
camera.resolution = (240, 240)  # 160, 128
camera.framerate = 32
camera.rotation = 180
camera.capture(img)
camera.close()
return img  # capture img path
```

**3. move_to_center**

- h는 계층의 갯수이고, 초기 설정은 -1로 한다.

h가 2보다 작을 경우에,

<이미지 처리 과정>

- 우선 이미지를 blur처리를 해준다. -> cv2.GaussianBlur

- 이미지의 BGR로 HSV값으로 바꿔준다. -> cv2.COLOR_BGR2HSV

- lower_blue, upper_blue라는 array를 만들어 주고 카메라로 캡쳐한 화면에서 이 범위에 있는 부분을 mask처리한다. -> cv2.inRange

<원 중심  과정>

- 계층 파악을 위해 contour를 이용해서 안의 위치한 원의 무게중심을 파악한다.
```py
cnt = contours[0]
M = cv2.moments(cnt)
```

- zerodivision 에러를 막기 위해 분모에 아주 작은 실수를 더해준다.
```py
cx = int(M['m10'] / (M['m00'] + 0.000000000000001))
cy = int(M['m01'] / (M['m00'] + 0.000000000000001))
```

- 계층 갯수를 print 해준다
```py
h = len(hierarchy[0])
print(h)
```
- print 된 h가 2와 같거나 클 경우 break 한다.

<check_y가 False일때> 

- 중심이 143보다 작을 때 y축으로 0.1 상승한다.

- 중심이 157보다 클 때 y축으로 0.1 하강한다.

- 중심이 143보다 크고 157보다 작을 때 print('y ok y : ', cy)를 해준다.

<check_x가 False일때>

- 중심이 113보다 작을 때 x축으로 0.1 증가한다.

- 중심이 127보다 클 때 x축으로 0.1 감소한다.

- 중심이 113보다 크고 127보다 작을 때 print('x ok x : ', cx)를 해준다.



**4. find_centroid**

- capture_img로 캡쳐된 장면을 이진화한 후 컨투어를 찾는다. (중심에 가까울수록 계층이 작은 RETR_LIST를 옵션으로 넣어 원이 0번 계층으로 잡히게 만듦)
```py
img = cv2.imread(capture_img())
img = cv2.GaussianBlur(img, (9, 9), 3)

hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
mask = cv2.inRange(hsv, lower_blue, upper_blue)

_, contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
```

- 만약 계층개수가 1개거나 0개이면 드론을 뒤로 움직여서 다시 find_centroid를 사용한다. 장애물이미지가 잘리지 않았을 때, 즉 컨투어가 2개일 때 중심의 좌표를 반환한다.
```py
print("go back")
# cv2.imshow('mask', mask)
# cv2.waitKey(0)
drone.sendControlPosition(-0.3, 0, 0, 1, 0, 0)
```

-  두번째 장애물부터는 장애물의 일부가 보이면 보인 부분의 무게중심을 구해 이동을 반복한다. (장애물이 상하좌우로 움직이기에 뒤로만 가서는 중점을 찾기에 한계가 존재) 
```py
drone.sendControlPosition(-0.3, 0, 0, 1, 0, 0)
move_to_center(drone)
```    
    
-  장애물이 다 보이는 위치로 이동을 하면 앞에서와 똑같이 중심을 리턴해준다. 
```py
cnt = contours[0]
img = cv2.drawContours(img, contours, 0, (255, 255, 0), 3)
M = cv2.moments(cnt)
cx = int(M['m10'] / (M['m00'] + 0.000000000000001))
cy = int(M['m01'] / (M['m00'] + 0.000000000000001))
print(cx, cy)
# cv2.imshow('mask', mask)
# cv2.waitKey(0)
return cx, cy
``` 


**5.match_center**

find_centroid에서 반환받은 중심점으로의 이동명령을 주는 함수이다.

<check_y가 False일때> 

- 중심(cy)이 143보다 작을 때 y축으로 0.1 상승한다.

- 중심이 157보다 클 때 y축으로 0.1 하강한다.

- 중심이 143보다 크고 157보다 작을 때 print('y ok y : ', cy)를 해준다.

<check_x가 False일때>

- 중심(cx)이 113보다 작을 때 x축으로 0.1 증가한다.

- 중심이 127보다 클 때 x축으로 0.1 감소한다.

- 중심이 113보다 크고 127보다 작을 때 print('x ok x : ', cx)를 해준다.
```py
cy = find_centroid(drone)[1]
...        
drone.sendControlWhile(0, 0, 0, 0, 1000)
...
cx = find_centroid(drone)[0]
...
drone.sendControlWhile(0, 0, 0, 0, 1000)
```

- pass_obstacle를 실행시준다.


**6.check_x**

- check_x는 match_center에서 이동명령을 줄 때 드론이 중심에 있는지 없는지를 판별해주는 함수이다.

- find_centroid 와 동일한 과정을 통해 중심값을 찾고 오차를 계산하여 True, False를 반환한다.
```py
if abs(cx - 120) <= 10:
    print('x true')
    return True
else:
    return False
```        


**7.check_y**

- check_x와 동일하게 match_center에서 이동명령을 줄 때 드론이 중심에 있는지 없는지를 판별해주는 함수이다.

- find_centroid 와 동일한 과정을 통해 중심값을 찾고 오차를 계산하여 True, False를 반환한다.
```py
if abs(cy - 150) <= 10:
    print('y true')
    return True
else:
    return False
```


**8. find_redpoint**

<이미지 처리 과정>

- 우선 이미지를 blur처리를 해준다. ->cv2.GaussianBlur

- lower_red, upper_red라는 array를 만들어 주고 카메라로 캡쳐한 화면에서 이 범위에 있는 부분을 mask처리한다. -> cv2.inRange 

- mask 처리된 것에서 np.nonzero의 갯수를 알아내서 return 해준다.

```py
point_red = np.nonzero(mask)
num_point_red = np.size(point_red)
return num_point_red
```


**9. find_purplepoint**

<이미지 처리 과정>

- 우선 이미지를 blur처리를 해준다. ->cv2.GaussianBlur

- lower_purple, upper_purple라는 array를 만들어 주고 카메라로 캡쳐한 화면에서 이 범위에 있는 부분을 mask처리한다. -> cv2.inRange

- mask 처리된 것에서 np.nonzero의 갯수를 알아내서 return 해준다.

```py
point_purple = np.nonzero(mask)
num_point_purple = np.size(point_purple)
return num_point_purple
```


**10. pass_obstacle**

- find_purplepoint의 값이 1000보다 작을시에는 드론을 착륙시키고 드론 객체를 종료시킨다.

- find_redpoint의 값이 1000보다 작을 시에는 드론을 x축으로 0.5 이동시킨 다음 pass_obstacle를 다시 실행시켜본다.

- find_redpoint의 값이 1000보다 클 시에는 드론을 90도로 좌회전을 시켜준다.


### main.py
